##1.Получите данные и загрузите их в рабочую среду.

import pandas as pd
import numpy as np
import seaborn as sns
import  matplotlib.pyplot as plt
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn import preprocessing
from sklearn.datasets import fetch_california_housing

from sklearn.metrics import mean_squared_error
from sklearn.metrics import r2_score
from sklearn.tree import DecisionTreeRegressor
from sklearn.model_selection import GridSearchCV

california_housing = fetch_california_housing(as_frame=True)
df = california_housing.frame
df.head()

##2.Проведите первичный анализ.

Проверьте данные на пропуски. Удалите в случае обнаружения.
*Нормализуйте один из признаков.

df.info()

df.insert(5, "Population_Norm", (preprocessing.normalize([np.array(df['Population'])])).T)
del df['Population']

df.head()

##3.Разделите выборку на обучающее и тестовое подмножества. 80% данных оставить на обучающее множество, 20% - на тестовое.

X = df[['MedInc', 'HouseAge', 'AveRooms', 'AveBedrms', 'Population_Norm', 'AveOccup',
       'Latitude', 'Longitude']]
y = df['MedHouseVal']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

##4.Обучите модель регрессии на обучающем множестве.

model = LinearRegression()
model.fit(X_train, y_train)
predictions_test = model.predict(X_test)

##5.Для тестового множества предскажите целевую переменную и сравните с истинным значением, посчитав точность предсказания модели. Для этого используйте встроенную функцию score.

model.score(X_test,y_test)

##6.Обучите дерево решений на обучающем множестве.

- Повторите п. 5 для полученной модели.
- Визуализируйте часть дерева решений. Убедитесь, что график получился читабельным. Посмотрите примеры визуализации по ссылке.

regressor = DecisionTreeRegressor(max_depth=3, random_state=1234)
regressor.fit(X_train, y_train)
y_pred = regressor.predict(X_test)
regressor.score(X_test,y_test)

from sklearn import tree

text_representation = tree.export_text(regressor)
print(text_representation)

fig = plt.figure(figsize=(25,20))
_ = tree.plot_tree(regressor,filled=True)

##7.Оптимизируйте глубину дерева (max_depth). *Оптимизируйте ещё один параметр модели на выбор.

- Повторите п. 5 для полученной модели.

parametrs = { 'max_depth': range (1,13, 1)}
regressor1 = DecisionTreeRegressor()
grid = GridSearchCV(regressor1 , parametrs)
grid.fit(X_train, y_train)

grid.best_params_

regressor2 = DecisionTreeRegressor(max_depth=9,max_features='sqrt', random_state=1234)
regressor2.fit(X_train, y_train)
y_pred = regressor.predict(X_test)
regressor2.score(X_test,y_test)



